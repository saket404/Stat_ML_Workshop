{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP90051 Workshop 5\n",
    "## The Perceptron\n",
    "***\n",
    "In this worksheet, we'll implement the perceptron (a building block of neural networks) from scratch. \n",
    "Our key objectives are:\n",
    "\n",
    "* to review the steps involved in the perceptron training algorithm, \n",
    "* to assess how the perceptron behaves in two distinct scenarios (separable vs. non-separable data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Synthetic data set\n",
    "We'll use the built-in `make_classification` function from `sklearn` to generate a synthetic binary classification data set.\n",
    "The main advantage of using synthetic data is that we have complete control over the distribution. \n",
    "This is useful for studying machine learning algorithms under specific conditions.\n",
    "In particular, we'll be varying the *degree of separability* between the two classes by adjusting the `class_sep` parameter below.\n",
    "To begin, we'll work with a data set that is almost linearly separable (with `class_sep = 2`).\n",
    "\n",
    "**Note:** In this worksheet we deviate from the standard `0`/`1` encoding for binary class labels used in `sklearn`. \n",
    "We use `-1` in place of `0` for the \"negative\" class to make the mathematical presentation of the perceptron algorithm easier to digest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURE_RESOLUTION = 128\n",
    "plt.rcParams['figure.dpi'] = FIGURE_RESOLUTION\n",
    "\n",
    "def create_toy_data(n_samples=200, class_sep=2):\n",
    "    X, Y = make_classification(n_samples=200, n_features=2, n_informative=2, \n",
    "                               n_redundant=0, n_clusters_per_class=1, flip_y=0,\n",
    "                               class_sep=class_sep, random_state=1)\n",
    "    Y[Y==0] = -1 # encode \"negative\" class using -1 rather than 0\n",
    "    plt.plot(X[Y==-1,0], X[Y==-1,1], \".\", label=\"$y = -1$\")\n",
    "    plt.plot(X[Y==1,0], X[Y==1,1], \".\", label=\"$y = 1$\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"$x_0$\")\n",
    "    plt.ylabel(\"$x_1$\")\n",
    "    plt.show()\n",
    "\n",
    "    return X,Y\n",
    "\n",
    "X, Y = create_toy_data(class_sep=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Is the perceptron a suitable classifier for this data set?\n",
    "  \n",
    "In preparation for training and evaluating a perceptron on this data, we randomly partition the data into train/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=90051)\n",
    "print(\"Training set has {} instances. Test set has {} instances.\".format(X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Definition of the perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from lectures that a perceptron is a linear binary classifier which maps an input vector $\\mathbf{x} \\in \\mathbb{R}^D$ to a binary output $y \\in \\{-1,1\\}$ given by\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(\\mathbf{x}; \\mathbf{w}, b) &= \\begin{cases}\n",
    "    1 & \\mathrm{if} \\ s(\\mathbf{x}; \\mathbf{w}, b) \\geq 0, \\\\\n",
    "    -1 & \\mathrm{otherwise},\n",
    "\\end{cases}\n",
    "\\end{align*}\n",
    "$$\n",
    "where $s(\\mathbf{x}; \\mathbf{w}, b) = \\mathbf{w} \\cdot \\mathbf{x} + b$. \n",
    "Here $\\mathbf{w} \\in \\mathbb{R}^D$ is a vector of weights (one for each feature) and $b$ is the bias term.\n",
    "\n",
    "Let start by implementing the weighted sum function $s(\\mathbf{x}; \\mathbf{w}, b)$ below. This is the 'inner product' $\\langle\\mathbf{w}, \\mathbf{x}\\rangle = \\sum_i w_i x_i$, which captures the geometrical alignment of the weight and instance vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_sum(X, w, b):\n",
    "    \"\"\"\n",
    "    Returns an array containing the weighted sum s(x) for each instance x in the feature matrix\n",
    "    \n",
    "    Arguments:\n",
    "    X : numpy array, shape: (n_instances, n_features)\n",
    "        feature matrix\n",
    "    w : numpy array, shape: (n_features,)\n",
    "        weights vector\n",
    "    b : float\n",
    "        bias term\n",
    "    \"\"\"\n",
    "    return ... # fill in\n",
    "\n",
    "def predict(X, w, b):\n",
    "    \"\"\"\n",
    "    Returns an array containing the predicted binary labels (-1/1) for each instance in the feature matrix\n",
    "    \n",
    "    Arguments:\n",
    "    X : numpy array, shape: (n_instances, n_features)\n",
    "        feature matrix\n",
    "    w : numpy array, shape: (n_features,)\n",
    "        weights vector\n",
    "    b : float\n",
    "        bias term\n",
    "    \"\"\"\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perceptron training algorithm\n",
    "\n",
    "We will now implement the Perceptron training algorithm first proposed by Rosenblatt in 1957. \n",
    "\n",
    "This is an online algorithm in the sense that it examples one point $\\mathbf{x}_t$ at a time. At each stage, the algorithm maintains a weight vector $\\mathbf{w}_t$ which defines the learned (hyper)plane separating the two classes. For convenience one typically starts with $\\mathbf{w}_0 = 0$. The label of the point $\\mathbf{x}_t$ is predicted using the sign of the dot product: $\\hat{y}_t = \\mathrm{sign}(\\mathbf{w}_t \\cdot \\mathbf{x}_t)$. If $\\mathbf{x}_t$ is misclassified, $y_t \\mathbf{x} \\cdot \\mathbf{w}_t$ is negative and we make a correction to the weight vector $\\mathbf{w}_{t+1} = \\mathbf{w}_t + \\eta y_t \\mathbf{x}_t$ for some learning rate $\\eta >0$. To motivate this, consider the dot product of the weight vector after the update with the misclassified instance: \n",
    "\n",
    "\\begin{align}\n",
    "y_t (\\mathbf{w}_t + \\eta y_t \\mathbf{x}_t) \\cdot \\mathbf{x}_t &= y_t \\mathbf{w}_t \\cdot \\mathbf{x}_t + \\eta ||\\mathbf{x}_t ||^2\\\\\n",
    "&\\geq y_t \\mathbf{w}_t \\cdot \\mathbf{x}_t\n",
    "\\end{align}\n",
    "\n",
    "So we reduce the severity of the error by an additive correction $\\eta || \\mathbf{x}_t ||^2$. We repeat this procedure until convergence or termination after a set limit of iterations. Pseudocode of the algorithm is shown below (taken from _Foundations of Machine Learning, Mohri, 2019_).\n",
    "\n",
    "<img src=\"https://i.imgur.com/N6NZrAC.png\" alt=\"Perceptron alg.\" width=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** After iterating through all of the training instances $t=[1, \\ldots, T]$, we have completed one *epoch*. The above pseudocode runs for one epoch. Typically, multiple epochs are required to get close to the optimal solution.\n",
    "\n",
    "The above training procedure is equivalent to performing sequential gradient descent on the following objective function:\n",
    "\n",
    "\\begin{align}\n",
    "    F(\\mathbf{w}) &= \\frac{1}{T} \\sum_{t=1}^T \\max\\left(0, -y_t (\\mathbf{w} \\cdot \\mathbf{x}_t)\\right) \\\\\n",
    "    \\mathbf{w}_{t+1} &\\leftarrow \\mathbf{w}_t - \\eta \\nabla_{\\mathbf{w}} F(\\mathbf{w}) \n",
    "\\end{align}\n",
    "\n",
    "To motivate the form of $F(\\mathbf{w})$, note that if $\\mathbf{x}_t$ is misclassified, $-y_t \\mathbf{w}_t \\cdot \\mathbf{x}_t > 0$. In this case the gradient is $\\nabla_{\\mathbf{w}} F(\\mathbf{w}) = -y_t \\mathbf{x}_t$, and zero if the instance is correctly classified. Omitting technical details about the case where $\\mathbf{w}_t \\cdot \\mathbf{x}_t = 0$ (we can resolve the non-differentiability by working with _subgradients_), the stochastic online update becomes:\n",
    "\n",
    "$$ \\mathbf{w}_{t+1} \\leftarrow\n",
    "  \\begin{cases}\n",
    "    \\mathbf{w}_t + \\eta y_t \\mathbf{x}_t, & \\text{if } y_t\\left(\\mathbf{x}_t \\cdot \\mathbf{w}_t\\right) \\leq 0; \\\\\n",
    "    \\mathbf{w}_t, & \\text{if } y_t\\left(\\mathbf{x}_t \\cdot \\mathbf{w}_t\\right) > 0 \\\\\n",
    "  \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now write a function called `train` which implements sequential gradient descent. The function should implement the pseudocode shown above, repeated for `n_epochs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, w, b, n_epochs=10, eta=0.1):\n",
    "    \"\"\"\n",
    "    Returns updated weight vector w and bias term b for\n",
    "    the Perceptron algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    X : numpy array, shape: (n_instances, n_features)\n",
    "        feature matrix\n",
    "    Y : numpy array, shape: (n_instances,)\n",
    "        target class labels relative to X\n",
    "    n_epochs : int\n",
    "        number of epochs (full sweeps through X)\n",
    "    w : numpy array, shape: (n_features,)\n",
    "        initial guess for weights vector w_0\n",
    "    b : float\n",
    "        initial guess for bias term b_0\n",
    "    eta : positive float\n",
    "        step size (default: 0.1)\n",
    "    \"\"\"\n",
    "    errors = 0\n",
    "    for t in range(n_epochs):\n",
    "        # loop over individual elements in X\n",
    "        for i in range(X.shape[0]):\n",
    "            yhat = ... # fill in\n",
    "            if yhat != Y[i]:\n",
    "                errors += 1\n",
    "                # Update if misclassified, else do nothing\n",
    "                w += ... # fill in\n",
    "                b += ... # fill in\n",
    "                \n",
    "    print('Number of errors {} / {} iterations'.format(errors, n_epochs * X.shape[0]))\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your implementation by running it for 5 epochs.\n",
    "You should get the following result for the weights and bias term:\n",
    "`w = [ 0.26746342 -0.96011853]; b = -0.2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise weights and bias to zero\n",
    "w = np.zeros(X.shape[1]); b = 0.0\n",
    "\n",
    "w, b = train(X_train, Y_train, w, b, n_epochs=5)\n",
    "print(\"w = {}; b = {}\".format(w, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained the perceptron, let's see how it performs.\n",
    "\n",
    "Below we plot the data (training and test sets) along with the decision boundary (which is defined by $\\{\\mathbf{x}: \\hat{\\mathbf{w}} \\cdot \\mathbf{x}= 0$\\})\n",
    "**Note:** It's not necessary to understand how the `plot_results` function works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(X_train, Y_train, X_test, Y_test, score_fn, threshold = 0):\n",
    "    # Plot training set\n",
    "    plt.plot(X_train[Y_train==-1,0], X_train[Y_train==-1,1], \".\", label=r\"$y=-1$, train\")\n",
    "    plt.plot(X_train[Y_train==1,0], X_train[Y_train==1,1], \".\", label=r\"$y=1$, train\")\n",
    "    plt.gca().set_prop_cycle(None) # reset colour cycle\n",
    "\n",
    "    # Plot test set\n",
    "    plt.plot(X_test[Y_test==-1,0], X_test[Y_test==-1,1], \"x\", label=r\"$y=-1$, test\")\n",
    "    plt.plot(X_test[Y_test==1,0], X_test[Y_test==1,1], \"x\", label=r\"$y=1$, test\")\n",
    "\n",
    "    # Compute axes limits\n",
    "    border = 1\n",
    "    x0_lower = X[:,0].min() - border\n",
    "    x0_upper = X[:,0].max() + border\n",
    "    x1_lower = X[:,1].min() - border\n",
    "    x1_upper = X[:,1].max() + border\n",
    "\n",
    "    # Generate grid over feature space\n",
    "    resolution = 0.01\n",
    "    x0, x1 = np.mgrid[x0_lower:x0_upper:resolution, x1_lower:x1_upper:resolution]\n",
    "    grid = np.c_[x0.ravel(), x1.ravel()]\n",
    "    s = score_fn(grid).reshape(x0.shape)\n",
    "\n",
    "    # Plot decision boundary (where s(x) == 0)\n",
    "    plt.contour(x0, x1, s, levels=[0], cmap=\"Greys\", vmin=-0.2, vmax=0.2)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"$x_0$\")\n",
    "    plt.ylabel(\"$x_1$\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_results(X_train, Y_train, X_test, Y_test, lambda X: weighted_sum(X, w, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well does the decision boundary separate the points in the two classes? How does it perform if you reduce the `class_sep` parameter in the `create_toy_dataset` function above?\n",
    "\n",
    "To evaluate the perceptron quantitatively, we'll use the error rate (proportion of misclassified instances).\n",
    "The error rate is a reasonable evaluation measure to use for this data since the classes are well balanced.\n",
    "\n",
    "Complete the `evaluate` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X, Y, w, b):\n",
    "    \"\"\"\n",
    "    Returns the proportion of misclassified instances (error rate)\n",
    "    \n",
    "    Arguments:\n",
    "    X : numpy array, shape: (n_instances, n_features)\n",
    "        feature matrix\n",
    "    Y : numpy array, shape: (n_instances,)\n",
    "        target class labels relative to X\n",
    "    w : numpy array, shape: (n_features,)\n",
    "        weights vector\n",
    "    b : float\n",
    "        bias term\n",
    "    \"\"\"\n",
    "    return ... # fill in\n",
    "\n",
    "print(evaluate(X_train, Y_train, w, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block above computes the error rate on the training data, which is not a good idea in general. (Why?)\n",
    "\n",
    "Compute the error rate on the test set instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluate(X_test, Y_test, w, b)) # fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How does this compare to the error on the training set? Is it what you expected?\n",
    "\n",
    "Let's now examine how the train/test error rates vary as a function of the number of epochs. Note that careful tuning of the learning rate is needed to get sensible behaviour. Setting $\\eta(t) = \\frac{1}{1+t}$ where $t$ is the epoch number often works well, the technical term of this is _learning rate annealing_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_hat = np.zeros(X_train.shape[1]); b_hat = 0\n",
    "n_epochs = 100\n",
    "\n",
    "# Initialize arrays to store errors for each epoch\n",
    "train_error = np.empty(n_epochs)\n",
    "heldout_error = np.empty(n_epochs)\n",
    "\n",
    "for t in range(n_epochs):\n",
    "    # here we use a learning rate, which decays with each epoch\n",
    "    eta = 1./(1+t)\n",
    "    w_hat, b_hat = train(X_train, Y_train, w_hat, b_hat, n_epochs=1, eta=eta)    \n",
    "    train_error[t] = evaluate(X_train, Y_train, w_hat, b_hat)\n",
    "    heldout_error[t] = evaluate(X_test, Y_test, w_hat, b_hat)\n",
    "\n",
    "plt.plot(train_error, label = 'Train error')\n",
    "plt.plot(heldout_error, label = 'Test error')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch, $t$')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Has the model changed significantly after training for more epochs (i.e. more than 5)? You can plot the new decision boundary by running the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(X_train, Y_train, X_test, Y_test, lambda X: weighted_sum(X, w_hat, b_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Repeat with class overlap\n",
    "By now you've probably concluded that the perceptron performs well on this data (`class_sep=2`), which is to be expected as it's roughly linearly separable. \n",
    "However, we know (from lectures) that the perceptron can fail on non-linearly separable data.\n",
    "To test this scenario, re-generate the synthetic data set with `class_sep=0.5` and repeat Sections 2–4.\n",
    "\n",
    "**Question:** What do you find? Pay particular attention to plot of the error vs. training epochs. Do you notice anything unusual?\n",
    "\n",
    "**Answer:** As mentioned in the previous answer, the model becomes highly unstable—the optimisation algorithm doesn't really converge to a good \"approximate\" solution. As a result, the train/test errors fluctuate wildly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Comparison with logistic regression\n",
    "We've seen that the perceptron is not robust to binary classification problems with overlapping classes. \n",
    "But how does logistic regression fare in this case?\n",
    "\n",
    "Run the code block below to fit a logistic regression model using `sklearn`. \n",
    "You may wish to switch off regularisation (alter the `C` parameter) for a fairer comparison with the perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(X_train, Y_train, X_test, Y_test, lambda X: clf.decision_function(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How does the logistic regression classifier compare to the perceptron? If we used the same weights for both the Perceptron and a logistic regression classifier (in the original feature space), which would perform better? *Hint: Consider the decision boundary for each.*\n",
    "\n",
    "**Question:** Compute the error rate for the logistic regression classifier and compare it to the error rate for the perceptron (for `class_sep=0.5`). *Hint: you may wish to use `clf.score(...)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0 - clf.score(X_test, Y_test) # fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "In the following exercise we will work through a proof of the perceptron convergence algorithm. We make the following assumptions:\n",
    "* The feature vectors lie in a sphere of radius $R$: $\\vert \\mathbf{x}_n \\vert \\leq R \\; \\forall \\;n$, i.e. their maximum length is $R$.\n",
    "* The data is linearly separable with margin $2\\gamma > 0$. That is, there exists a unit normal vector to the hyperlane $\\mathbf{w}^*$ such that $y_i \\mathbf{w}^* \\cdot \\mathbf{x}_n \\geq \\gamma$ and $\\vert \\mathbf{w}^* \\vert = 1$. Note that $\\mathbf{w}^* \\cdot \\mathbf{x}_n $ can be thought of as the shortest (Euclidean) distance from the hyperplane to a given training instance $\\mathbf{x}_n$, as you will see when we study SVMs.\n",
    "\n",
    "Given a sequence $\\mathbf{x}_1, \\ldots, \\mathbf{x}_T$ of $T$ instances, we want to find a bound on the total number of updates the Perceptron algorithm will make in this scenario. Let us only consider the subset of iterations $\\mathcal{K}$ of the $T$ rounds where the Perceptron makes an error, and we have to make an update. So we are interested in finding the number of updates $\\vert \\mathcal{K} \\vert$. Note we have a trivial bound of $\\vert \\mathcal{K} \\vert = T$ - where the algorithm makes an error at every iteration. We would like to obtain a more 'efficient' bound than this.\n",
    "\n",
    "1. Assume there is an error at iteration $k \\in \\mathcal{K}$ and we initialize $\\mathbf{w}_0 = \\mathbf{0}$. Prove that \n",
    "\n",
    "   $$ \\mathbf{w}^* \\cdot \\mathbf{w}_{k+1} \\geq (k+1) \\gamma $$\n",
    "   \n",
    "2. Use the fact that the instances $\\mathbf{x}_k$ are bounded to show that\n",
    "\n",
    "   $$ || \\mathbf{w}_k ||^2 \\leq k R^2 $$\n",
    "   \n",
    "3. Use the definition of the dot product, $\\mathbf{u} \\cdot \\mathbf{v} = \\vert \\mathbf{u} \\vert \\vert \\mathbf{v} \\vert \\cos \\theta $, where $\\theta$ is the angle between $\\mathbf{u}$ and $\\mathbf{v}$, to prove that\n",
    "\n",
    "   $$ \\mathbf{w}^* \\cdot \\mathbf{w}_k \\leq \\vert \\mathbf{w}^*\\vert \\vert \\mathbf{w}_k \\vert $$\n",
    "   \n",
    "4. Use the above inequalities to prove that the number of updates is bounded:\n",
    "   $$ k \\leq \\frac{R^2}{\\gamma^2} $$\n",
    "   \n",
    "In other words, no misclassified sample exists after at most $\\frac{R^2}{\\gamma^2}$ steps! \n",
    "\n",
    "**Discussion:** Is this what you expect? Does this bound make sense intuitively?\n",
    "\n",
    "We can also obtain bounds on the number of updates when training on the sequence $\\mathbf{x}_1, \\ldots, \\mathbf{x}_T$ for the more general case of non-linearly separable data in terms of the hinge loss of our classifier! Another time, perhaps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
